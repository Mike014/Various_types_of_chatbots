{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command to create conda environment\n",
    "   ```bash\n",
    "   conda create -n my_env python=3.12\n",
    "   conda activate my_env\n",
    "   ```\n",
    "## Commando to download nltk scikit-learn\n",
    " ```bash\n",
    "   conda install nltk\n",
    "   conda install scikit-learn\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import nltk\n",
    "from nltk.chat.util import Chat, reflections\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Donwload the punkt package\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pairs of questions and answers\n",
    "pairs = [\n",
    "    ['hello', ['Hello! How can I help you today?']],\n",
    "    ['I forgot my password', ['You can click on \"Forgot Password\" to reset it.']],\n",
    "    ['thank you', ['You are welcome!']],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `nltk.chat.util` library is a part of the **NLTK (Natural Language Toolkit) library**, specifically designed for creating simple rule-based chatbots.\n",
    "\n",
    "### Description\n",
    "The `nltk.chat.util` library provides utilities for building chatbots that can respond to user inputs based on predefined patterns and responses. It is useful for creating basic conversational agents without the need for complex machine learning models.\n",
    "\n",
    "### Parameters\n",
    "- **pairs**: A list of patterns and responses. Each pattern is a regular expression that matches user input, and the corresponding response is a string or a list of strings that the chatbot can reply with.\n",
    "- **reflections**: A dictionary that maps pronouns and other words to their corresponding reflections. This is used to make the chatbot's responses more natural by reflecting the user's input.\n",
    "\n",
    "### Example\n",
    "## The nltk.chat.util library is a part of the **NLTK (Natural Language Toolkit) library**, specifically designed for creating simple rule-based chatbots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_14460\\2145872996.py:18: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  input_box.on_submit(chat_with_bot)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9f4979c0424b64a3b1c688dbb2b7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='You:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fb6a8f4bec4099a8b502132f5c1721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create input and output widgets\n",
    "input_box = widgets.Text(description=\"You:\")\n",
    "output_box = widgets.Output()\n",
    "\n",
    "# Function to interact with the chatbot\n",
    "def chat_with_bot(change):\n",
    "    user_input = input_box.value\n",
    "    with output_box:\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Goodbye!\")\n",
    "        else:\n",
    "            response = chatbot.respond(user_input)\n",
    "            print(f\"You: {user_input}\")\n",
    "            print(f\"Bot: {response}\")\n",
    "    input_box.value = ''  # Clear the input box\n",
    "\n",
    "# Link the function to the input box\n",
    "input_box.on_submit(chat_with_bot)\n",
    "\n",
    "# Display the widgets\n",
    "display(input_box, output_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The import block from shown:\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "```\n",
    "### Are two scikit-learn libraries (CountVectorizer and cosine_similarity) are essential for implementing text analysis and similarity functionality in chatbots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are' 'can' 'click' 'forgot' 'hello' 'help' 'how' 'it' 'on' 'password'\n",
      " 'reset' 'to' 'today' 'welcome' 'you']\n",
      "[[0 1 0 0 1 1 1 0 0 0 0 0 1 0 1]\n",
      " [0 1 1 1 0 0 0 1 1 1 1 1 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer is a scikit-learn class used to convert text into a numerical representation based on word frequency (BoW).\n",
    "\n",
    "# Define the corpus\n",
    "corpus = [\n",
    "    'Hello! How can I help you today?',\n",
    "    'You can click on \"Forgot Password\" to reset it.',\n",
    "    'You are welcome!'\n",
    "]\n",
    "\n",
    "# Create the CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Print the feature names\n",
    "print(vectorizer.get_feature_names_out())\n",
    "# Print the BoW matrix\n",
    "X = X.toarray()\n",
    "print(X)\n",
    "\n",
    "# Use in chatbots:\n",
    "# CountVectorizer allows you to transform the user and chatbot's sentences into a numerical representation. \n",
    "# This is the first step to analyze similarities or classify intentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.27216553 0.23570226]\n",
      " [0.27216553 1.         0.19245009]\n",
      " [0.23570226 0.19245009 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# cosine_similarity is a scikit-learn function that calculates the similarity between two numerical vectors using cosine similarity.\n",
    "\n",
    "similarity = cosine_similarity(X)\n",
    "\n",
    "# Print the similarity matrix\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.38490018 0.        ]\n",
      " [0.         1.         0.27216553 0.23570226]\n",
      " [0.38490018 0.27216553 1.         0.19245009]\n",
      " [0.         0.23570226 0.19245009 1.        ]]\n",
      "Best response index: 0\n"
     ]
    }
   ],
   "source": [
    "# Define the responses and user input\n",
    "responses = [\n",
    "    'Hello! How can I help you today?',\n",
    "    'You can click on \"Forgot Password\" to reset it.',\n",
    "    'You are welcome!'\n",
    "]\n",
    "\n",
    "user_input = 'I forgot my password'\n",
    "\n",
    "# Combine the user input and the responses into a single corpus\n",
    "corpus = [user_input] + responses\n",
    "\n",
    "# Create a new CountVectorizer object\n",
    "vectorizer2 = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer to the corpus and transform the text data into a numerical representation\n",
    "X2 = vectorizer2.fit_transform(corpus)\n",
    "\n",
    "# Calculate the cosine similarity between the user input and the responses\n",
    "similarity2 = cosine_similarity(X2)\n",
    "\n",
    "# Print the similarity matrix\n",
    "print(\"Similarity Matrix:\")\n",
    "print(similarity2)\n",
    "\n",
    "# Find the index of the best response based on the highest similarity score\n",
    "# We skip the first row (user input) and find the best match among the responses\n",
    "best_response_index = similarity2[0, 1:].argmax() + 1\n",
    "\n",
    "# Print the best response index\n",
    "print(f\"Best response index: {best_response_index}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
