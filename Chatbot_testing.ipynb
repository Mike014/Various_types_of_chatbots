{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Environment for the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (3.9.1)\n",
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Collecting beautifulsoup4 (from wikipedia)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting requests<3.0.0,>=2.0.0 (from wikipedia)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from scikit-learn) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.0.0->wikipedia)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.0.0->wikipedia)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.0.0->wikipedia)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.0.0->wikipedia)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->wikipedia)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\envs\\my_env\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11756 sha256=9bf4a930669dd7e6ae7aad479128be3ca007acdf076c305caba3ae5c4a2068b8\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\63\\47\\7c\\a9688349aa74d228ce0a9023229c6c0ac52ca2a40fe87679b8\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: urllib3, soupsieve, idna, charset-normalizer, certifi, requests, beautifulsoup4, wikipedia\n",
      "Successfully installed beautifulsoup4-4.12.3 certifi-2024.12.14 charset-normalizer-3.4.1 idna-3.10 requests-2.32.3 soupsieve-2.6 urllib3-2.3.0 wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk wikipedia scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Main Libraries\n",
    "import nltk\n",
    "import wikipedia as wk\n",
    "import random\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# For NLP\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# For TF-IDF and similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Scikit-learn's TfidfVectorizer transforms text documents into a TF-IDF matrix, weighting terms by frequency and inverse document frequency.\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset\n",
    "nltk.download('punkt')  # For tokenization\n",
    "nltk.download('wordnet')  # For lemmatization\n",
    "nltk.download('stopwords')  # To filter stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l of their previous records. their sixth album, the hunting party (2014), returned to a heavier rock sound, while their seventh album, one more light (2017), was a substantially more pop-oriented record. the band's eighth album, from zero, was released in november 2024.\n",
      "\n",
      "linkin park is among both the best-selling bands of the 21st century and the world's best-selling music artists, having sold over 100 million records worldwide.[6] they have won two grammy awards, six american music awards, four billboard music awards, four mtv video music awards, 10 mtv europe music awards, and three world music awards. in 2003, mtv2 named linkin park the sixth-greatest band of the music video era and the third-best of the new millennium. billboard ranked linkin park no. 19 on the best artists of the decade list. in 2012, the band was voted as the greatest artist of the 2000s in a bracket madness poll on vh1. in 2014, the band was declared \"the biggest rock band in the world right now\" by kerrang!.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the data \n",
    "data = open(\"Text.txt\", \"r\", errors=\"ignore\")\n",
    "raw = data.read()\n",
    "\n",
    "raw = raw.lower()\n",
    "\n",
    "print(raw[-1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"linkin park is an american rock band formed in agoura hills, california, in 1996. the band's current lineup consists of vocalist/rhythm guitarist/keyboardist mike shinoda, lead guitarist brad delson, dj/turntablist joe hahn, bassist dave farrell, co-lead vocalist emily armstrong, and drummer colin brittain.\", \"the lineup for the band's first seven studio albums included lead vocalist chester bennington and drummer rob bourdon until bennington's suicide in july 2017, which caused the band to enter an indefinite hiatus.\", \"in september 2024, linkin park's reformation was announced along with the addition of armstrong and brittain.\", \"categorized mainly as alternative rock and nu metal, linkin park's earlier music spanned a fusion of heavy metal and hip hop, while their later music features more electronica and pop elements.\", 'linkin park rose to international fame with their debut studio album, hybrid theory (2000), which became certified diamond by the recording industry association of america (riaa).', 'released during the peak of the nu metal scene, the album\\'s singles\\' heavy airplay on mtv led to the singles \"one step closer\", \"crawling\", and \"in the end\" all charting highly on the us mainstream rock chart.', \"the lattermost also crossed over to the number two spot on the nation's billboard hot 100.\", \"[2] their second album, meteora (2003), continued the band's success.\", '[3] the band explored experimental sounds on their third album, minutes to midnight (2007).', '[4] by the end of the decade, linkin park was among the most successful and popular rock acts.', '[5]\\n\\nthe band continued to explore a wider variation of musical types on their fourth album, a thousand suns (2010), layering their music with more electronic sounds.', \"the band's fifth album, living things (2012), combined musical elements from all of their previous records.\", 'their sixth album, the hunting party (2014), returned to a heavier rock sound, while their seventh album, one more light (2017), was a substantially more pop-oriented record.', \"the band's eighth album, from zero, was released in november 2024.\\n\\nlinkin park is among both the best-selling bands of the 21st century and the world's best-selling music artists, having sold over 100 million records worldwide.\", '[6] they have won two grammy awards, six american music awards, four billboard music awards, four mtv video music awards, 10 mtv europe music awards, and three world music awards.', 'in 2003, mtv2 named linkin park the sixth-greatest band of the music video era and the third-best of the new millennium.', 'billboard ranked linkin park no.', '19 on the best artists of the decade list.', 'in 2012, the band was voted as the greatest artist of the 2000s in a bracket madness poll on vh1.', 'in 2014, the band was declared \"the biggest rock band in the world right now\" by kerrang!.']\n",
      "['linkin', 'park', 'is', 'an', 'american', 'rock', 'band', 'formed', 'in', 'agoura', 'hills', ',', 'california', ',', 'in', '1996.', 'the', 'band', \"'s\", 'current', 'lineup', 'consists', 'of', 'vocalist/rhythm', 'guitarist/keyboardist', 'mike', 'shinoda', ',', 'lead', 'guitarist', 'brad', 'delson', ',', 'dj/turntablist', 'joe', 'hahn', ',', 'bassist', 'dave', 'farrell', ',', 'co-lead', 'vocalist', 'emily', 'armstrong', ',', 'and', 'drummer', 'colin', 'brittain', '.', 'the', 'lineup', 'for', 'the', 'band', \"'s\", 'first', 'seven', 'studio', 'albums', 'included', 'lead', 'vocalist', 'chester', 'bennington', 'and', 'drummer', 'rob', 'bourdon', 'until', 'bennington', \"'s\", 'suicide', 'in', 'july', '2017', ',', 'which', 'caused', 'the', 'band', 'to', 'enter', 'an', 'indefinite', 'hiatus', '.', 'in', 'september', '2024', ',', 'linkin', 'park', \"'s\", 'reformation', 'was', 'announced', 'along', 'with', 'the', 'addition', 'of', 'armstrong', 'and', 'brittain', '.', 'categorized', 'mainly', 'as', 'alternative', 'rock', 'and', 'nu', 'metal', ',', 'linkin', 'park', \"'s\", 'earlier', 'music', 'spanned', 'a', 'fusion', 'of', 'heavy', 'metal', 'and', 'hip', 'hop', ',', 'while', 'their', 'later', 'music', 'features', 'more', 'electronica', 'and', 'pop', 'elements', '.', 'linkin', 'park', 'rose', 'to', 'international', 'fame', 'with', 'their', 'debut', 'studio', 'album', ',', 'hybrid', 'theory', '(', '2000', ')', ',', 'which', 'became', 'certified', 'diamond', 'by', 'the', 'recording', 'industry', 'association', 'of', 'america', '(', 'riaa', ')', '.', 'released', 'during', 'the', 'peak', 'of', 'the', 'nu', 'metal', 'scene', ',', 'the', 'album', \"'s\", 'singles', \"'\", 'heavy', 'airplay', 'on', 'mtv', 'led', 'to', 'the', 'singles', '``', 'one', 'step', 'closer', \"''\", ',', '``', 'crawling', \"''\", ',', 'and', '``', 'in', 'the', 'end', \"''\", 'all', 'charting', 'highly', 'on', 'the', 'us', 'mainstream', 'rock', 'chart', '.', 'the', 'lattermost', 'also', 'crossed', 'over', 'to', 'the', 'number', 'two', 'spot', 'on', 'the', 'nation', \"'s\", 'billboard', 'hot', '100', '.', '[', '2', ']', 'their', 'second', 'album', ',', 'meteora', '(', '2003', ')', ',', 'continued', 'the', 'band', \"'s\", 'success', '.', '[', '3', ']', 'the', 'band', 'explored', 'experimental', 'sounds', 'on', 'their', 'third', 'album', ',', 'minutes', 'to', 'midnight', '(', '2007', ')', '.', '[', '4', ']', 'by', 'the', 'end', 'of', 'the', 'decade', ',', 'linkin', 'park', 'was', 'among', 'the', 'most', 'successful', 'and', 'popular', 'rock', 'acts', '.', '[', '5', ']', 'the', 'band', 'continued', 'to', 'explore', 'a', 'wider', 'variation', 'of', 'musical', 'types', 'on', 'their', 'fourth', 'album', ',', 'a', 'thousand', 'suns', '(', '2010', ')', ',', 'layering', 'their', 'music', 'with', 'more', 'electronic', 'sounds', '.', 'the', 'band', \"'s\", 'fifth', 'album', ',', 'living', 'things', '(', '2012', ')', ',', 'combined', 'musical', 'elements', 'from', 'all', 'of', 'their', 'previous', 'records', '.', 'their', 'sixth', 'album', ',', 'the', 'hunting', 'party', '(', '2014', ')', ',', 'returned', 'to', 'a', 'heavier', 'rock', 'sound', ',', 'while', 'their', 'seventh', 'album', ',', 'one', 'more', 'light', '(', '2017', ')', ',', 'was', 'a', 'substantially', 'more', 'pop-oriented', 'record', '.', 'the', 'band', \"'s\", 'eighth', 'album', ',', 'from', 'zero', ',', 'was', 'released', 'in', 'november', '2024.', 'linkin', 'park', 'is', 'among', 'both', 'the', 'best-selling', 'bands', 'of', 'the', '21st', 'century', 'and', 'the', 'world', \"'s\", 'best-selling', 'music', 'artists', ',', 'having', 'sold', 'over', '100', 'million', 'records', 'worldwide', '.', '[', '6', ']', 'they', 'have', 'won', 'two', 'grammy', 'awards', ',', 'six', 'american', 'music', 'awards', ',', 'four', 'billboard', 'music', 'awards', ',', 'four', 'mtv', 'video', 'music', 'awards', ',', '10', 'mtv', 'europe', 'music', 'awards', ',', 'and', 'three', 'world', 'music', 'awards', '.', 'in', '2003', ',', 'mtv2', 'named', 'linkin', 'park', 'the', 'sixth-greatest', 'band', 'of', 'the', 'music', 'video', 'era', 'and', 'the', 'third-best', 'of', 'the', 'new', 'millennium', '.', 'billboard', 'ranked', 'linkin', 'park', 'no', '.', '19', 'on', 'the', 'best', 'artists', 'of', 'the', 'decade', 'list', '.', 'in', '2012', ',', 'the', 'band', 'was', 'voted', 'as', 'the', 'greatest', 'artist', 'of', 'the', '2000s', 'in', 'a', 'bracket', 'madness', 'poll', 'on', 'vh1', '.', 'in', '2014', ',', 'the', 'band', 'was', 'declared', '``', 'the', 'biggest', 'rock', 'band', 'in', 'the', 'world', 'right', 'now', \"''\", 'by', 'kerrang', '!', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization \n",
    "\n",
    "# Sentences\n",
    "sent_tokens = nltk.sent_tokenize(raw)\n",
    "\n",
    "# Words\n",
    "word_tokens = nltk.word_tokenize(raw)\n",
    "\n",
    "print(sent_tokens)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linkin', 'park', 'is', 'an', 'american']\n"
     ]
    }
   ],
   "source": [
    "# Normalizaztion\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "word_tokens = [word for word in word_tokens if word not in string.punctuation]\n",
    "\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "\n",
    "print(lemmatized_tokens[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: [5]\n",
      "\n",
      "the band continued to explore a wider variation of musical types on their fourth album, a thousand suns (2010), layering their music with more electronic sounds.\n"
     ]
    }
   ],
   "source": [
    "# Chatbot Function\n",
    "import numpy as np\n",
    "\n",
    "def generate_response(user_input):\n",
    "    global sent_tokens\n",
    "    sent_tokens.append(user_input)\n",
    "    \n",
    "    # Calculate TF-IDF\n",
    "    vectorizer = TfidfVectorizer(tokenizer=lemmatizer.lemmatize, stop_words='english')\n",
    "    tfidf = vectorizer.fit_transform(sent_tokens)\n",
    "    \n",
    "    # Cosine similarity\n",
    "    similarity_scores = cosine_similarity(tfidf[-1], tfidf[:-1])\n",
    "    index = np.argmax(similarity_scores)\n",
    "    flat = similarity_scores.flatten()\n",
    "    max_score = flat[index]\n",
    "    \n",
    "    # Remove user input from tokens\n",
    "    sent_tokens.pop(-1)\n",
    "    \n",
    "    # Response based on similarity\n",
    "    if max_score > 0.1:\n",
    "        return sent_tokens[index]\n",
    "    else:\n",
    "        return \"I'm sorry, I didn't understand your question.\"\n",
    "\n",
    "# Check: Example response\n",
    "user_input = \"Albums between 2010 and 2015?\"\n",
    "print(\"Chatbot:\", generate_response(user_input))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
